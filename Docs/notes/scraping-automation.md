# ã‚«ãƒ•ã‚§ãƒ¡ãƒ‹ãƒ¥ãƒ¼æƒ…å ±ã®è‡ªå‹•æ›´æ–°

## æ¦‚è¦

ã‚«ãƒ•ã‚§ãƒã‚§ãƒ¼ãƒ³ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã¨ä¾¡æ ¼æƒ…å ±ã‚’å®šæœŸçš„ã«è‡ªå‹•æ›´æ–°ã™ã‚‹ãŸã‚ã®ã‚·ã‚¹ãƒ†ãƒ ã€‚

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GitHub Actions  â”‚  é€±1å›å®Ÿè¡Œï¼ˆæ¯é€±æœˆæ›œ 0:00 JSTï¼‰
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Scraper Script â”‚  å„ãƒã‚§ãƒ¼ãƒ³åº—ã®å…¬å¼ã‚µã‚¤ãƒˆã‹ã‚‰æƒ…å ±å–å¾—
â”‚  (Python)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â–º Resources/ChainsMenu.json (ãƒ­ãƒ¼ã‚«ãƒ«DB)
         â”‚
         â””â”€â”€â–º Supabase (ã‚¯ãƒ©ã‚¦ãƒ‰DB)
              â”œâ”€ chains ãƒ†ãƒ¼ãƒ–ãƒ«
              â”œâ”€ chain_products ãƒ†ãƒ¼ãƒ–ãƒ«
              â””â”€ product_sizes ãƒ†ãƒ¼ãƒ–ãƒ«
```

## å®Ÿè£…æ–¹æ³•

### 1. GitHub Actions (æ¨å¥¨)

**ãƒ¡ãƒªãƒƒãƒˆ:**
- ç„¡æ–™ï¼ˆãƒ‘ãƒ–ãƒªãƒƒã‚¯ãƒªãƒã‚¸ãƒˆãƒªï¼‰
- è¨­å®šãŒç°¡å˜
- Gitå±¥æ­´ã§å¤‰æ›´ã‚’è¿½è·¡å¯èƒ½

**è¨­å®š:**
`.github/workflows/scrape-menus.yml` ã§è‡ªå‹•å®Ÿè¡Œã‚’è¨­å®šã€‚

```yaml
on:
  schedule:
    - cron: '0 15 * * 0'  # æ¯é€±æ—¥æ›œ 15:00 UTC = æœˆæ›œ 0:00 JST
  workflow_dispatch:       # æ‰‹å‹•å®Ÿè¡Œã‚‚å¯èƒ½
```

**å¿…è¦ãªã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆ:**
- `SUPABASE_KEY`: Supabase ã® anon/service key

### 2. Supabase Edge Functions

**ãƒ¡ãƒªãƒƒãƒˆ:**
- Supabaseå†…ã§å®Œçµ
- ä½ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·
- ç›´æ¥DBã«æ›¸ãè¾¼ã¿å¯èƒ½

**å®Ÿè£…ä¾‹:**
```typescript
// supabase/functions/update-menus/index.ts
Deno.cron("update-menus", "0 0 * * 1", async () => {
  const data = await scrapeStarbucks();
  await supabase.from('chain_products').upsert(data);
});
```

### 3. AWS Lambda + EventBridge

**ãƒ¡ãƒªãƒƒãƒˆ:**
- ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«
- ä»–ã®AWSã‚µãƒ¼ãƒ“ã‚¹ã¨ã®çµ±åˆ

**ã‚³ã‚¹ãƒˆ:**
- é€±1å›å®Ÿè¡Œãªã‚‰ç„¡æ–™æ å†…

## ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè£…

### æ³¨æ„äº‹é …

âš ï¸ **å¿…ãšä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:**

1. **robots.txt ã®ç¢ºèª**
   ```
   https://example.com/robots.txt
   ```

2. **åˆ©ç”¨è¦ç´„ã®ç¢ºèª**
   - ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãŒç¦æ­¢ã•ã‚Œã¦ã„ãªã„ã‹
   - å•†ç”¨åˆ©ç”¨ã®å¯å¦

3. **API ã®å„ªå…ˆ**
   - å…¬å¼APIãŒã‚ã‚‹å ´åˆã¯å¿…ãšãã¡ã‚‰ã‚’ä½¿ç”¨

4. **ã‚¢ã‚¯ã‚»ã‚¹é »åº¦**
   - éåº¦ãªãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é¿ã‘ã‚‹
   - é–“éš”ã‚’ç©ºã‘ã‚‹ï¼ˆä¾‹: 1ç§’ä»¥ä¸Šï¼‰

5. **User-Agent ã®è¨­å®š**
   ```python
   headers = {
       'User-Agent': 'CafeDokoBot/1.0 (+https://cafedoko.app/bot)'
   }
   ```

### å®Ÿè£…ä¾‹

```python
import requests
from bs4 import BeautifulSoup
import time

def scrape_chain_menu(url: str) -> dict:
    """
    ã‚«ãƒ•ã‚§ãƒã‚§ãƒ¼ãƒ³ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼æƒ…å ±ã‚’å–å¾—
    """
    headers = {
        'User-Agent': 'CafeDokoBot/1.0 (+https://cafedoko.app/bot)'
    }
    
    response = requests.get(url, headers=headers)
    response.raise_for_status()
    
    soup = BeautifulSoup(response.content, 'html.parser')
    
    # ã‚µã‚¤ãƒˆæ§‹é€ ã«å¿œã˜ã¦ãƒ‘ãƒ¼ã‚¹
    products = []
    for item in soup.select('.menu-item'):
        name = item.select_one('.name').text.strip()
        price = item.select_one('.price').text.strip()
        products.append({
            'name': name,
            'price': int(price.replace('å††', '').replace(',', ''))
        })
    
    time.sleep(1)  # æ¬¡ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¾ã§å¾…æ©Ÿ
    
    return {'products': products}
```

## å„ãƒã‚§ãƒ¼ãƒ³ã®å¯¾å¿œçŠ¶æ³

| ãƒã‚§ãƒ¼ãƒ³ | ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚° | å…¬å¼API | æ›´æ–°é »åº¦ | å®Ÿè£…çŠ¶æ³ |
|---------|--------------|---------|---------|---------|
| ã‚¹ã‚¿ãƒ¼ãƒãƒƒã‚¯ã‚¹ | âš ï¸ è¦ç¢ºèª | âŒ ãªã— | æœˆ1å›ç¨‹åº¦ | ğŸš§ æº–å‚™ä¸­ |
| ãƒ‰ãƒˆãƒ¼ãƒ« | âš ï¸ è¦ç¢ºèª | âŒ ãªã— | å¹´2å›ç¨‹åº¦ | ğŸ“ è¨ˆç”»ä¸­ |
| ã‚¿ãƒªãƒ¼ã‚º | âš ï¸ è¦ç¢ºèª | âŒ ãªã— | æœˆ1å›ç¨‹åº¦ | ğŸ“ è¨ˆç”»ä¸­ |
| ã‚³ãƒ¡ãƒ€ | âš ï¸ è¦ç¢ºèª | âŒ ãªã— | å¹´2å›ç¨‹åº¦ | ğŸ“ è¨ˆç”»ä¸­ |
| ã‚¨ã‚¯ã‚»ãƒ«ã‚·ã‚ªãƒ¼ãƒ« | âš ï¸ è¦ç¢ºèª | âŒ ãªã— | æœˆ1å›ç¨‹åº¦ | ğŸ“ è¨ˆç”»ä¸­ |

## ä»£æ›¿æ¡ˆ: æ‰‹å‹•æ›´æ–° + ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£è²¢çŒ®

ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãŒé›£ã—ã„å ´åˆ:

1. **æœˆ1å›ã®æ‰‹å‹•æ›´æ–°**
   - ãƒãƒ¼ãƒ /å€‹äººã§å…¬å¼ã‚µã‚¤ãƒˆã‚’ç¢ºèª
   - `ChainsMenu.json` ã‚’æ›´æ–°

2. **ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£è²¢çŒ®**
   - ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®æƒ…å ±æä¾›ã‚’å—ã‘ä»˜ã‘
   - Pull Request ã§æ›´æ–°

3. **åº—èˆ—ã‹ã‚‰ã®æƒ…å ±æä¾›**
   - å„ãƒã‚§ãƒ¼ãƒ³ã«å”åŠ›ã‚’ä¾é ¼
   - å…¬å¼ãƒ‡ãƒ¼ã‚¿ã®æä¾›ã‚’å—ã‘ã‚‹

## ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ

### GitHub Actions ã®ç›£è¦–

- å¤±æ•—æ™‚ã«é€šçŸ¥ï¼ˆSlack, Discord, ãƒ¡ãƒ¼ãƒ«ï¼‰
- é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã®è‡ªå‹•ç”Ÿæˆ

### ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚¯

```python
def validate_menu_data(data: dict) -> bool:
    """
    æ›´æ–°ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ã‚’æ¤œè¨¼
    """
    if not data.get('chains'):
        return False
    
    for chain in data['chains']:
        if not chain.get('name') or not chain.get('categories'):
            return False
        
        # ä¾¡æ ¼ãŒç•°å¸¸å€¤ã§ãªã„ã‹ãƒã‚§ãƒƒã‚¯
        for category in chain['categories']:
            for product in category['products']:
                for size in product['sizes']:
                    price = size.get('price', 0)
                    if price < 100 or price > 2000:
                        print(f"âš ï¸ ç•°å¸¸ä¾¡æ ¼æ¤œå‡º: {product['name']} - {price}å††")
                        return False
    
    return True
```

## ä»Šå¾Œã®æ‹¡å¼µ

- [ ] å…¨ãƒã‚§ãƒ¼ãƒ³ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè£…
- [ ] ä¾¡æ ¼å¤‰å‹•ã®é€šçŸ¥æ©Ÿèƒ½
- [ ] æ–°å•†å“ã®è‡ªå‹•æ¤œå‡º
- [ ] å­£ç¯€é™å®šå•†å“ã®ãƒ•ãƒ©ã‚°
- [ ] åœ°åŸŸåˆ¥ä¾¡æ ¼ã®å¯¾å¿œ
- [ ] ç”»åƒã®è‡ªå‹•å–å¾—
- [ ] æ „é¤Šæƒ…å ±ã®è¿½åŠ 

## å‚è€ƒãƒªãƒ³ã‚¯

- [GitHub Actions - Schedule](https://docs.github.com/en/actions/using-workflows/events-that-trigger-workflows#schedule)
- [Supabase Edge Functions](https://supabase.com/docs/guides/functions)
- [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Scrapy Framework](https://scrapy.org/)

