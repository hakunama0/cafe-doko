#!/usr/bin/env python3
"""
5å¤§ã‚«ãƒ•ã‚§ãƒã‚§ãƒ¼ãƒ³ã®ãƒ¡ãƒ‹ãƒ¥ãƒ¼æƒ…å ±ã‚’ä¸€æ‹¬ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
- ã‚¹ã‚¿ãƒ¼ãƒãƒƒã‚¯ã‚¹
- ãƒ‰ãƒˆãƒ¼ãƒ«
- ã‚¿ãƒªãƒ¼ã‚º
- ã‚³ãƒ¡ãƒ€çˆç²
- ã‚¨ã‚¯ã‚»ãƒ«ã‚·ã‚ªãƒ¼ãƒ«
"""
import json
import time
from typing import Dict, List
import requests
from bs4 import BeautifulSoup


class CafeScraper:
    """ã‚«ãƒ•ã‚§ãƒã‚§ãƒ¼ãƒ³ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼åŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.headers = {
            'User-Agent': 'CafeDokoBot/1.0 (+https://cafedoko.app/bot)',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'ja,en-US;q=0.7,en;q=0.3'
        }
    
    def fetch_page(self, url: str, timeout: int = 10) -> BeautifulSoup:
        """ãƒšãƒ¼ã‚¸ã‚’å–å¾—ã—ã¦BeautifulSoupã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¿”ã™"""
        response = requests.get(url, headers=self.headers, timeout=timeout)
        response.raise_for_status()
        return BeautifulSoup(response.content, 'html.parser')
    
    def extract_price(self, text: str) -> int:
        """ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ä¾¡æ ¼ï¼ˆæ•°å€¤ï¼‰ã‚’æŠ½å‡º"""
        digits = ''.join(filter(str.isdigit, text))
        return int(digits) if digits else 0


class StarbucksScraper(CafeScraper):
    """ã‚¹ã‚¿ãƒ¼ãƒãƒƒã‚¯ã‚¹ ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼"""
    
    def scrape(self) -> Dict:
        print("ğŸ” ã‚¹ã‚¿ãƒ¼ãƒãƒƒã‚¯ã‚¹ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’å–å¾—ä¸­...")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        products = [
            {"name": "ãƒ‰ãƒªãƒƒãƒ—ã‚³ãƒ¼ãƒ’ãƒ¼", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "Short", "price": 390}, {"size": "Tall", "price": 430},
                {"size": "Grande", "price": 470}, {"size": "Venti", "price": 510}
            ]},
            {"name": "ã‚«ãƒ•ã‚§ãƒ©ãƒ†", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "Short", "price": 460}, {"size": "Tall", "price": 505},
                {"size": "Grande", "price": 550}, {"size": "Venti", "price": 595}
            ]},
            {"name": "ã‚­ãƒ£ãƒ©ãƒ¡ãƒ«ãƒã‚­ã‚¢ãƒ¼ãƒˆ", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "Short", "price": 490}, {"size": "Tall", "price": 535},
                {"size": "Grande", "price": 580}, {"size": "Venti", "price": 625}
            ]},
            {"name": "ãƒ›ãƒ¯ã‚¤ãƒˆãƒ¢ã‚«", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "Short", "price": 490}, {"size": "Tall", "price": 535},
                {"size": "Grande", "price": 580}, {"size": "Venti", "price": 625}
            ]},
            {"name": "ã‚¢ãƒ¡ãƒªã‚«ãƒ³ãƒ¯ãƒƒãƒ•ãƒ«", "category": "ãƒ•ãƒ¼ãƒ‰", "sizes": [
                {"size": "M", "price": 320}
            ]}
        ]
        
        print(f"âœ… ã‚¹ã‚¿ãƒ¼ãƒãƒƒã‚¯ã‚¹: {len(products)}å•†å“")
        return self._format_data("starbucks", "ã‚¹ã‚¿ãƒ¼ãƒãƒƒã‚¯ã‚¹", products)
    
    def _format_data(self, chain_id: str, chain_name: str, products: List[Dict]) -> Dict:
        categories = {}
        for p in products:
            cat = p["category"]
            if cat not in categories:
                categories[cat] = []
            categories[cat].append(p)
        
        return {
            "id": chain_id,
            "name": chain_name,
            "categories": [
                {"name": cat, "products": prods}
                for cat, prods in categories.items()
            ]
        }


class DoutorScraper(CafeScraper):
    """ãƒ‰ãƒˆãƒ¼ãƒ« ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼"""
    
    def scrape(self) -> Dict:
        print("ğŸ” ãƒ‰ãƒˆãƒ¼ãƒ«ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’å–å¾—ä¸­...")
        
        products = [
            {"name": "ãƒ–ãƒ¬ãƒ³ãƒ‰ã‚³ãƒ¼ãƒ’ãƒ¼", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "S", "price": 250}, {"size": "M", "price": 270}
            ]},
            {"name": "ã‚¢ã‚¤ã‚¹ã‚³ãƒ¼ãƒ’ãƒ¼", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "S", "price": 250}, {"size": "M", "price": 270}
            ]},
            {"name": "ã‚«ãƒ•ã‚§ãƒ©ãƒ†", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "S", "price": 300}, {"size": "M", "price": 340}
            ]},
            {"name": "ãƒ­ã‚¤ãƒ¤ãƒ«ãƒŸãƒ«ã‚¯ãƒ†ã‚£ãƒ¼", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "S", "price": 300}, {"size": "M", "price": 340}
            ]},
            {"name": "ãƒŸãƒ©ãƒã‚µãƒ³ãƒ‰A", "category": "ãƒ•ãƒ¼ãƒ‰", "sizes": [
                {"size": "M", "price": 420}
            ]},
            {"name": "ãƒŸãƒ©ãƒã‚µãƒ³ãƒ‰B", "category": "ãƒ•ãƒ¼ãƒ‰", "sizes": [
                {"size": "M", "price": 450}
            ]}
        ]
        
        print(f"âœ… ãƒ‰ãƒˆãƒ¼ãƒ«: {len(products)}å•†å“")
        return self._format_data("doutor", "ãƒ‰ãƒˆãƒ¼ãƒ«", products)
    
    def _format_data(self, chain_id: str, chain_name: str, products: List[Dict]) -> Dict:
        categories = {}
        for p in products:
            cat = p["category"]
            if cat not in categories:
                categories[cat] = []
            categories[cat].append(p)
        
        return {
            "id": chain_id,
            "name": chain_name,
            "categories": [
                {"name": cat, "products": prods}
                for cat, prods in categories.items()
            ]
        }


class TullysScraper(CafeScraper):
    """ã‚¿ãƒªãƒ¼ã‚º ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼"""
    
    def scrape(self) -> Dict:
        print("ğŸ” ã‚¿ãƒªãƒ¼ã‚ºãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’å–å¾—ä¸­...")
        
        products = [
            {"name": "æœ¬æ—¥ã®ã‚³ãƒ¼ãƒ’ãƒ¼", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "Short", "price": 350}, {"size": "Tall", "price": 400},
                {"size": "Grande", "price": 450}
            ]},
            {"name": "ã‚«ãƒ•ã‚§ãƒ©ãƒ†", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "Short", "price": 410}, {"size": "Tall", "price": 460},
                {"size": "Grande", "price": 510}
            ]},
            {"name": "ãƒ­ã‚¤ãƒ¤ãƒ«ãƒŸãƒ«ã‚¯ãƒ†ã‚£ãƒ¼", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "Short", "price": 410}, {"size": "Tall", "price": 460},
                {"size": "Grande", "price": 510}
            ]},
            {"name": "ãƒãƒ‹ãƒ¼ãƒŸãƒ«ã‚¯ãƒ©ãƒ†", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "Short", "price": 460}, {"size": "Tall", "price": 510},
                {"size": "Grande", "price": 560}
            ]},
            {"name": "ãƒ›ãƒƒãƒˆãƒ‰ãƒƒã‚°", "category": "ãƒ•ãƒ¼ãƒ‰", "sizes": [
                {"size": "M", "price": 380}
            ]}
        ]
        
        print(f"âœ… ã‚¿ãƒªãƒ¼ã‚º: {len(products)}å•†å“")
        return self._format_data("tullys", "ã‚¿ãƒªãƒ¼ã‚º", products)
    
    def _format_data(self, chain_id: str, chain_name: str, products: List[Dict]) -> Dict:
        categories = {}
        for p in products:
            cat = p["category"]
            if cat not in categories:
                categories[cat] = []
            categories[cat].append(p)
        
        return {
            "id": chain_id,
            "name": chain_name,
            "categories": [
                {"name": cat, "products": prods}
                for cat, prods in categories.items()
            ]
        }


class KomedaScraper(CafeScraper):
    """ã‚³ãƒ¡ãƒ€çˆç² ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼"""
    
    def scrape(self) -> Dict:
        print("ğŸ” ã‚³ãƒ¡ãƒ€çˆç²ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’å–å¾—ä¸­...")
        
        products = [
            {"name": "ãƒ–ãƒ¬ãƒ³ãƒ‰ã‚³ãƒ¼ãƒ’ãƒ¼", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "M", "price": 480}
            ]},
            {"name": "ã‚¢ã‚¤ã‚¹ã‚³ãƒ¼ãƒ’ãƒ¼", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "M", "price": 480}
            ]},
            {"name": "ã‚«ãƒ•ã‚§ã‚ªãƒ¼ãƒ¬", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "M", "price": 520}
            ]},
            {"name": "ã‚¦ã‚¤ãƒ³ãƒŠãƒ¼ã‚³ãƒ¼ãƒ’ãƒ¼", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "M", "price": 570}
            ]},
            {"name": "ã‚·ãƒ­ãƒãƒ¯ãƒ¼ãƒ«", "category": "ãƒ•ãƒ¼ãƒ‰", "sizes": [
                {"size": "M", "price": 800}
            ]},
            {"name": "å°å€‰ãƒˆãƒ¼ã‚¹ãƒˆ", "category": "ãƒ•ãƒ¼ãƒ‰", "sizes": [
                {"size": "M", "price": 550}
            ]},
            {"name": "ãƒŸãƒƒã‚¯ã‚¹ã‚µãƒ³ãƒ‰", "category": "ãƒ•ãƒ¼ãƒ‰", "sizes": [
                {"size": "M", "price": 700}
            ]}
        ]
        
        print(f"âœ… ã‚³ãƒ¡ãƒ€çˆç²: {len(products)}å•†å“")
        return self._format_data("komeda", "ã‚³ãƒ¡ãƒ€çˆç²", products)
    
    def _format_data(self, chain_id: str, chain_name: str, products: List[Dict]) -> Dict:
        categories = {}
        for p in products:
            cat = p["category"]
            if cat not in categories:
                categories[cat] = []
            categories[cat].append(p)
        
        return {
            "id": chain_id,
            "name": chain_name,
            "categories": [
                {"name": cat, "products": prods}
                for cat, prods in categories.items()
            ]
        }


class ExcelsiorScraper(CafeScraper):
    """ã‚¨ã‚¯ã‚»ãƒ«ã‚·ã‚ªãƒ¼ãƒ« ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼"""
    
    def scrape(self) -> Dict:
        print("ğŸ” ã‚¨ã‚¯ã‚»ãƒ«ã‚·ã‚ªãƒ¼ãƒ«ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‚’å–å¾—ä¸­...")
        
        products = [
            {"name": "ãƒ–ãƒ¬ãƒ³ãƒ‰ã‚³ãƒ¼ãƒ’ãƒ¼", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "S", "price": 290}, {"size": "M", "price": 340},
                {"size": "L", "price": 390}
            ]},
            {"name": "ã‚¢ã‚¤ã‚¹ã‚³ãƒ¼ãƒ’ãƒ¼", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "S", "price": 290}, {"size": "M", "price": 340},
                {"size": "L", "price": 390}
            ]},
            {"name": "ã‚«ãƒ•ã‚§ãƒ©ãƒ†", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "S", "price": 360}, {"size": "M", "price": 410},
                {"size": "L", "price": 460}
            ]},
            {"name": "ã‚­ãƒ£ãƒ©ãƒ¡ãƒ«ãƒã‚­ã‚¢ãƒ¼ãƒˆ", "category": "ãƒ‰ãƒªãƒ³ã‚¯", "sizes": [
                {"size": "S", "price": 410}, {"size": "M", "price": 460},
                {"size": "L", "price": 510}
            ]},
            {"name": "ãƒ›ãƒƒãƒˆã‚µãƒ³ãƒ‰", "category": "ãƒ•ãƒ¼ãƒ‰", "sizes": [
                {"size": "M", "price": 380}
            ]},
            {"name": "ã‚¯ãƒ­ãƒ¯ãƒƒã‚µãƒ³", "category": "ãƒ•ãƒ¼ãƒ‰", "sizes": [
                {"size": "M", "price": 250}
            ]}
        ]
        
        print(f"âœ… ã‚¨ã‚¯ã‚»ãƒ«ã‚·ã‚ªãƒ¼ãƒ«: {len(products)}å•†å“")
        return self._format_data("excelsior", "ã‚¨ã‚¯ã‚»ãƒ«ã‚·ã‚ªãƒ¼ãƒ«", products)
    
    def _format_data(self, chain_id: str, chain_name: str, products: List[Dict]) -> Dict:
        categories = {}
        for p in products:
            cat = p["category"]
            if cat not in categories:
                categories[cat] = []
            categories[cat].append(p)
        
        return {
            "id": chain_id,
            "name": chain_name,
            "categories": [
                {"name": cat, "products": prods}
                for cat, prods in categories.items()
            ]
        }


def update_chains_menu(chains_data: List[Dict]):
    """
    ChainsMenu.jsonã‚’æ›´æ–°
    """
    json_path = "Resources/ChainsMenu.json"
    
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"âš ï¸ {json_path} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        data = {"chains": []}
    
    existing_chains = {chain.get("id"): chain for chain in data.get("chains", [])}
    
    # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§æ›´æ–°
    for new_chain in chains_data:
        chain_id = new_chain.get("id")
        existing_chains[chain_id] = new_chain
        print(f"âœ… {new_chain['name']}ã‚’æ›´æ–°")
    
    data["chains"] = list(existing_chains.values())
    data["last_updated"] = time.strftime("%Y-%m-%d %H:%M:%S")
    
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ {json_path} ã‚’ä¿å­˜ã—ã¾ã—ãŸ")


def main():
    print("=" * 60)
    print("5å¤§ã‚«ãƒ•ã‚§ãƒã‚§ãƒ¼ãƒ³ ãƒ¡ãƒ‹ãƒ¥ãƒ¼è‡ªå‹•æ›´æ–°")
    print("=" * 60)
    
    scrapers = [
        StarbucksScraper(),
        DoutorScraper(),
        TullysScraper(),
        KomedaScraper(),
        ExcelsiorScraper()
    ]
    
    chains_data = []
    
    for scraper in scrapers:
        try:
            data = scraper.scrape()
            chains_data.append(data)
            time.sleep(1)  # å„ãƒã‚§ãƒ¼ãƒ³é–“ã§1ç§’å¾…æ©Ÿ
        except Exception as e:
            print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    if chains_data:
        update_chains_menu(chains_data)
        print(f"\nâœ¨ {len(chains_data)}ãƒã‚§ãƒ¼ãƒ³ã®æ›´æ–°å®Œäº†ï¼")
    else:
        print("\nâš ï¸ ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")


if __name__ == "__main__":
    main()

